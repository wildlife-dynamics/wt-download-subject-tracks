# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details

# ruff: noqa: E402

"""WARNING: This file is generated in a testing context and should not be used in production.
Lines specific to the testing context are marked with a test tube emoji (ðŸ§ª) to indicate
that they would not be included (or would be different) in the production version of this file.
"""

import json
import os
import warnings  # ðŸ§ª

from ecoscope_workflows_core.graph import DependsOn, Graph, Node
from ecoscope_workflows_core.tasks.config import (
    set_workflow_details as set_workflow_details,
)
from ecoscope_workflows_core.tasks.filter import (
    get_timezone_from_time_range as get_timezone_from_time_range,
)
from ecoscope_workflows_core.tasks.filter import set_time_range as set_time_range
from ecoscope_workflows_core.tasks.io import set_er_connection as set_er_connection
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_skipped as any_dependency_skipped,
)
from ecoscope_workflows_core.tasks.skip import any_is_empty_df as any_is_empty_df
from ecoscope_workflows_core.testing import create_task_magicmock  # ðŸ§ª

get_subjectgroup_observations = create_task_magicmock(  # ðŸ§ª
    anchor="ecoscope_workflows_ext_ecoscope.tasks.io",  # ðŸ§ª
    func_name="get_subjectgroup_observations",  # ðŸ§ª
)  # ðŸ§ª
from ecoscope_workflows_core.tasks.config import set_string_var as set_string_var
from ecoscope_workflows_core.tasks.groupby import set_groupers as set_groupers
from ecoscope_workflows_core.tasks.groupby import split_groups as split_groups
from ecoscope_workflows_core.tasks.io import persist_text as persist_text
from ecoscope_workflows_core.tasks.results import (
    create_map_widget_single_view as create_map_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import gather_dashboard as gather_dashboard
from ecoscope_workflows_core.tasks.results import (
    merge_widget_views as merge_widget_views,
)
from ecoscope_workflows_core.tasks.skip import never as never
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index as add_temporal_index,
)
from ecoscope_workflows_core.tasks.transformation import (
    convert_values_to_timezone as convert_values_to_timezone,
)
from ecoscope_workflows_core.tasks.transformation import map_columns as map_columns
from ecoscope_workflows_core.tasks.transformation import sort_values as sort_values
from ecoscope_workflows_ext_custom.tasks.io import (
    persist_df_wrapper as persist_df_wrapper,
)
from ecoscope_workflows_ext_custom.tasks.skip import maybe_skip_df as maybe_skip_df
from ecoscope_workflows_ext_custom.tasks.transformation import (
    apply_sql_query as apply_sql_query,
)
from ecoscope_workflows_ext_custom.tasks.transformation import (
    drop_column_prefix as drop_column_prefix,
)
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    relocations_to_trajectory as relocations_to_trajectory,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_polyline_layer as create_polyline_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import draw_ecomap as draw_ecomap
from ecoscope_workflows_ext_ecoscope.tasks.results import set_base_maps as set_base_maps
from ecoscope_workflows_ext_ecoscope.tasks.skip import (
    all_geometry_are_none as all_geometry_are_none,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_reloc_coord_filter as apply_reloc_coord_filter,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    assign_subject_colors as assign_subject_colors,
)
from ecoscope_workflows_ext_ecoscope.tasks.warning import (
    mixed_subtype_warning as mixed_subtype_warning,
)

from ..params import Params


def main(params: Params):
    warnings.warn("This test script should not be used in production!")  # ðŸ§ª

    params_dict = json.loads(params.model_dump_json(exclude_unset=True))

    dependencies = {
        "workflow_details": [],
        "time_range": [],
        "get_timezone": ["time_range"],
        "er_client_name": [],
        "subject_obs": ["er_client_name", "time_range"],
        "warn_if_mixed_subtype": ["subject_obs"],
        "convert_to_user_timezone": ["subject_obs", "get_timezone"],
        "drop_extra_prefix": ["convert_to_user_timezone"],
        "filter_obs": ["drop_extra_prefix"],
        "subject_traj": ["filter_obs"],
        "drop_extra_prefix_traj": ["subject_traj"],
        "customize_columns_internally": ["drop_extra_prefix_traj"],
        "customize_columns": ["customize_columns_internally"],
        "sql_query": ["customize_columns"],
        "groupers": [],
        "obs_add_temporal_index": ["sql_query", "groupers"],
        "split_traj_groups": ["obs_add_temporal_index", "groupers"],
        "persist_tracks": ["split_traj_groups"],
        "skip_map_generation": ["split_traj_groups"],
        "set_traj_map_title": [],
        "base_map_defs": [],
        "colormap_traj": ["skip_map_generation"],
        "sort_subject_names": ["colormap_traj"],
        "rename_display_columns": ["sort_subject_names"],
        "traj_map_layers": ["rename_display_columns"],
        "traj_ecomap": ["base_map_defs", "set_traj_map_title", "traj_map_layers"],
        "ecomap_html_urls": ["traj_ecomap"],
        "traj_map_widgets_single_views": ["set_traj_map_title", "ecomap_html_urls"],
        "traj_grouped_map_widget": ["traj_map_widgets_single_views"],
        "subject_tracking_dashboard": [
            "workflow_details",
            "traj_grouped_map_widget",
            "groupers",
            "time_range",
            "warn_if_mixed_subtype",
        ],
    }

    nodes = {
        "workflow_details": Node(
            async_task=set_workflow_details.validate()
            .set_task_instance_id("workflow_details")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("workflow_details") or {}),
            method="call",
        ),
        "time_range": Node(
            async_task=set_time_range.validate()
            .set_task_instance_id("time_range")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "time_format": "%d %b %Y %H:%M:%S",
            }
            | (params_dict.get("time_range") or {}),
            method="call",
        ),
        "get_timezone": Node(
            async_task=get_timezone_from_time_range.validate()
            .set_task_instance_id("get_timezone")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "time_range": DependsOn("time_range"),
            }
            | (params_dict.get("get_timezone") or {}),
            method="call",
        ),
        "er_client_name": Node(
            async_task=set_er_connection.validate()
            .set_task_instance_id("er_client_name")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("er_client_name") or {}),
            method="call",
        ),
        "subject_obs": Node(
            async_task=get_subjectgroup_observations.validate()
            .set_task_instance_id("subject_obs")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "client": DependsOn("er_client_name"),
                "time_range": DependsOn("time_range"),
                "raise_on_empty": False,
            }
            | (params_dict.get("subject_obs") or {}),
            method="call",
        ),
        "warn_if_mixed_subtype": Node(
            async_task=mixed_subtype_warning.validate()
            .set_task_instance_id("warn_if_mixed_subtype")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "subject_obs": DependsOn("subject_obs"),
            }
            | (params_dict.get("warn_if_mixed_subtype") or {}),
            method="call",
        ),
        "convert_to_user_timezone": Node(
            async_task=convert_values_to_timezone.validate()
            .set_task_instance_id("convert_to_user_timezone")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("subject_obs"),
                "timezone": DependsOn("get_timezone"),
                "columns": [
                    "fixtime",
                ],
            }
            | (params_dict.get("convert_to_user_timezone") or {}),
            method="call",
        ),
        "drop_extra_prefix": Node(
            async_task=drop_column_prefix.validate()
            .set_task_instance_id("drop_extra_prefix")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("convert_to_user_timezone"),
                "prefix": "extra__",
                "duplicate_strategy": "suffix",
            }
            | (params_dict.get("drop_extra_prefix") or {}),
            method="call",
        ),
        "filter_obs": Node(
            async_task=apply_reloc_coord_filter.validate()
            .set_task_instance_id("filter_obs")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("drop_extra_prefix"),
                "roi_gdf": None,
                "roi_name": None,
                "reset_index": False,
            }
            | (params_dict.get("filter_obs") or {}),
            method="call",
        ),
        "subject_traj": Node(
            async_task=relocations_to_trajectory.validate()
            .set_task_instance_id("subject_traj")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "relocations": DependsOn("filter_obs"),
            }
            | (params_dict.get("subject_traj") or {}),
            method="call",
        ),
        "drop_extra_prefix_traj": Node(
            async_task=drop_column_prefix.validate()
            .set_task_instance_id("drop_extra_prefix_traj")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("subject_traj"),
                "prefix": "extra__",
                "duplicate_strategy": "suffix",
            }
            | (params_dict.get("drop_extra_prefix_traj") or {}),
            method="call",
        ),
        "customize_columns_internally": Node(
            async_task=map_columns.validate()
            .set_task_instance_id("customize_columns_internally")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("drop_extra_prefix_traj"),
                "drop_columns": [
                    "id",
                ],
            }
            | (params_dict.get("customize_columns_internally") or {}),
            method="call",
        ),
        "customize_columns": Node(
            async_task=map_columns.validate()
            .set_task_instance_id("customize_columns")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("customize_columns_internally"),
            }
            | (params_dict.get("customize_columns") or {}),
            method="call",
        ),
        "sql_query": Node(
            async_task=apply_sql_query.validate()
            .set_task_instance_id("sql_query")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("customize_columns"),
            }
            | (params_dict.get("sql_query") or {}),
            method="call",
        ),
        "groupers": Node(
            async_task=set_groupers.validate()
            .set_task_instance_id("groupers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("groupers") or {}),
            method="call",
        ),
        "obs_add_temporal_index": Node(
            async_task=add_temporal_index.validate()
            .set_task_instance_id("obs_add_temporal_index")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("sql_query"),
                "time_col": "segment_start",
                "groupers": DependsOn("groupers"),
                "cast_to_datetime": True,
                "format": "mixed",
            }
            | (params_dict.get("obs_add_temporal_index") or {}),
            method="call",
        ),
        "split_traj_groups": Node(
            async_task=split_groups.validate()
            .set_task_instance_id("split_traj_groups")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("obs_add_temporal_index"),
                "groupers": DependsOn("groupers"),
            }
            | (params_dict.get("split_traj_groups") or {}),
            method="call",
        ),
        "persist_tracks": Node(
            async_task=persist_df_wrapper.validate()
            .set_task_instance_id("persist_tracks")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "sanitize": True,
            }
            | (params_dict.get("persist_tracks") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_traj_groups"),
            },
        ),
        "skip_map_generation": Node(
            async_task=maybe_skip_df.validate()
            .set_task_instance_id("skip_map_generation")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("skip_map_generation") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_traj_groups"),
            },
        ),
        "set_traj_map_title": Node(
            async_task=set_string_var.validate()
            .set_task_instance_id("set_traj_map_title")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "var": "Subject Group Trajectory Map",
            }
            | (params_dict.get("set_traj_map_title") or {}),
            method="call",
        ),
        "base_map_defs": Node(
            async_task=set_base_maps.validate()
            .set_task_instance_id("base_map_defs")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("base_map_defs") or {}),
            method="call",
        ),
        "colormap_traj": Node(
            async_task=assign_subject_colors.validate()
            .set_task_instance_id("colormap_traj")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "subject_id_column": "subject__id",
                "output_column": "subject_colormap",
                "default_palette": "tab20b",
            }
            | (params_dict.get("colormap_traj") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("skip_map_generation"),
            },
        ),
        "sort_subject_names": Node(
            async_task=sort_values.validate()
            .set_task_instance_id("sort_subject_names")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "subject__name",
                "ascending": True,
                "na_position": "last",
            }
            | (params_dict.get("sort_subject_names") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("colormap_traj"),
            },
        ),
        "rename_display_columns": Node(
            async_task=map_columns.validate()
            .set_task_instance_id("rename_display_columns")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "rename_columns": {
                    "segment_start": "Start",
                    "timespan_seconds": "Duration (s)",
                    "speed_kmhr": "Speed (kph)",
                    "subject__name": "Subject Name",
                    "subject__sex": "Subject Sex",
                },
            }
            | (params_dict.get("rename_display_columns") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("sort_subject_names"),
            },
        ),
        "traj_map_layers": Node(
            async_task=create_polyline_layer.validate()
            .set_task_instance_id("traj_map_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                    all_geometry_are_none,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "color_column": "subject_colormap",
                },
                "legend": {
                    "label_column": "Subject Name",
                    "color_column": "subject_colormap",
                },
                "tooltip_columns": [
                    "Start",
                    "Duration (s)",
                    "Speed (kph)",
                    "Nighttime",
                    "Subject Name",
                    "Subject Sex",
                ],
            }
            | (params_dict.get("traj_map_layers") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["geodataframe"],
                "argvalues": DependsOn("rename_display_columns"),
            },
        ),
        "traj_ecomap": Node(
            async_task=draw_ecomap.validate()
            .set_task_instance_id("traj_ecomap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "tile_layers": DependsOn("base_map_defs"),
                "north_arrow_style": {
                    "placement": "top-left",
                },
                "legend_style": {
                    "title": "Subject",
                    "format_title": False,
                    "placement": "bottom-right",
                },
                "static": False,
                "title": None,
                "max_zoom": 20,
                "widget_id": DependsOn("set_traj_map_title"),
            }
            | (params_dict.get("traj_ecomap") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["geo_layers"],
                "argvalues": DependsOn("traj_map_layers"),
            },
        ),
        "ecomap_html_urls": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("ecomap_html_urls")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "v2",
            }
            | (params_dict.get("ecomap_html_urls") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["text"],
                "argvalues": DependsOn("traj_ecomap"),
            },
        ),
        "traj_map_widgets_single_views": Node(
            async_task=create_map_widget_single_view.validate()
            .set_task_instance_id("traj_map_widgets_single_views")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": DependsOn("set_traj_map_title"),
            }
            | (params_dict.get("traj_map_widgets_single_views") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("ecomap_html_urls"),
            },
        ),
        "traj_grouped_map_widget": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("traj_grouped_map_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("traj_map_widgets_single_views"),
            }
            | (params_dict.get("traj_grouped_map_widget") or {}),
            method="call",
        ),
        "subject_tracking_dashboard": Node(
            async_task=gather_dashboard.validate()
            .set_task_instance_id("subject_tracking_dashboard")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "details": DependsOn("workflow_details"),
                "widgets": [
                    DependsOn("traj_grouped_map_widget"),
                ],
                "groupers": DependsOn("groupers"),
                "time_range": DependsOn("time_range"),
                "warning": DependsOn("warn_if_mixed_subtype"),
            }
            | (params_dict.get("subject_tracking_dashboard") or {}),
            method="call",
        ),
    }
    graph = Graph(dependencies=dependencies, nodes=nodes)
    results = graph.execute()
    return results
